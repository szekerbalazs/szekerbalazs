{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Model Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import patsy as pt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "    Matern,\n",
    "    RationalQuadratic,\n",
    "    ConstantKernel as C,\n",
    "    WhiteKernel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation Functions\n",
    "def load_and_preprocess_data():\n",
    "    # Load training and test data\n",
    "    train = pd.read_csv(\"X_train.csv\")\n",
    "    train_labels = pd.read_csv(\"y_train.csv\")\n",
    "    test = pd.read_csv(\"X_test.csv\")\n",
    "\n",
    "    # Drop ID column\n",
    "    train = train.drop(\"id\", axis=1)\n",
    "    train_labels = train_labels.drop(\"id\", axis=1)\n",
    "    test = test.drop(\"id\", axis=1)\n",
    "\n",
    "    # Correlation-based Feature Selection\n",
    "    train_combined = pd.concat([train, train_labels], axis=1)\n",
    "    corr_combined = train_combined.corr()\n",
    "    corr_target = corr_combined[\"y\"].sort_values(ascending=False)\n",
    "    selected_features = corr_target[corr_target.abs() > 0.12].index.drop(\"y\")\n",
    "\n",
    "    train_selected = train[selected_features]\n",
    "    test_selected = test[selected_features]\n",
    "       \n",
    "    # Imputation of Missing Values\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    train_imputed = imputer.fit_transform(train_selected)\n",
    "    test_imputed = imputer.transform(test_selected)\n",
    "\n",
    "    # Standard Scaling\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train_imputed)\n",
    "    test_scaled = scaler.transform(test_imputed)\n",
    "\n",
    "    return train_scaled, train_labels.values, test_scaled     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Evaluate GPR with K-Fold Cross-Validation\n",
    "def evaluate_with_kfold(X, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    r2_scores = []\n",
    "\n",
    "    kernel = C(1.0) * Matern(\n",
    "        length_scale=500.0,\n",
    "        nu=1.5,\n",
    "    ) + C(1.0) * RationalQuadratic(\n",
    "        length_scale=5.0,\n",
    "        alpha=1.0,\n",
    "    )\n",
    "\n",
    "    estimators = [\n",
    "        ('linear', LinearRegression()),\n",
    "        ('ridge', Ridge()),\n",
    "        ('knn', KNeighborsRegressor(n_neighbors=15)),\n",
    "        ('rf', RandomForestRegressor(n_estimators=100,random_state=42)),\n",
    "        ('gbr', GradientBoostingRegressor(n_estimators=100,random_state=42)),\n",
    "        ('svr', SVR()),\n",
    "        ('gpr', GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=10,random_state=42)),\n",
    "    ]\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "        print(f\"Starting Fold {fold + 1}/{k}\")\n",
    "        stacking_regressor = StackingRegressor(estimators=estimators, final_estimator=LinearRegression(),n_jobs=-1)\n",
    "\n",
    "        # Split the data for this fold\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "        # Train the model for this fold\n",
    "        stacking_regressor.fit(X_train_fold, y_train_fold.ravel())\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_val_pred = stacking_regressor.predict(X_val_fold)\n",
    "        r2 = r2_score(y_val_fold, y_val_pred)\n",
    "        print(f\"Fold {fold + 1} R² Score: {r2}\")\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "    print(\"\\nCross-Validation Report\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Number of Folds: {k}\")\n",
    "    print(f\"R² Scores for Each Fold: {r2_scores}\")\n",
    "    print(f\"Average R² Score: {avg_r2:.4f}\")\n",
    "\n",
    "    return avg_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Train GPR on Full Training Set and Predict on Test Set\n",
    "def train_and_predict(X_train, y_train, X_test, output_file=\"predictions.csv\"):\n",
    "    \n",
    "    kernel = C(1.0) * Matern(\n",
    "        length_scale=500.0,\n",
    "        nu=1.5,\n",
    "    ) + C(1.0) * RationalQuadratic(\n",
    "        length_scale=5.0,\n",
    "        alpha=1.0,\n",
    "    ) + C(1.0) * WhiteKernel(\n",
    "        noise_level=1.0\n",
    "    )\n",
    "\n",
    "    estimators = [\n",
    "        ('linear', LinearRegression()),\n",
    "        ('ridge', Ridge()),\n",
    "        ('knn', KNeighborsRegressor(n_neighbors=15)),\n",
    "        ('rf', RandomForestRegressor(n_estimators=100,random_state=42)),\n",
    "        ('gbr', GradientBoostingRegressor(n_estimators=100,random_state=42)),\n",
    "        ('svr', SVR()),\n",
    "        ('gpr', GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=10,random_state=42)),\n",
    "    ]\n",
    "\n",
    "    stacking_regressor = StackingRegressor(estimators=estimators, final_estimator=LinearRegression(),n_jobs=-1)\n",
    "\n",
    "    # Train on the entire training set\n",
    "    stacking_regressor.fit(X_train, y_train.ravel())\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_test_pred = stacking_regressor.predict(X_test)\n",
    "\n",
    "    # Save predictions to a CSV file\n",
    "    test_pred = pd.DataFrame(y_test_pred, columns=[\"y\"])\n",
    "    test_pred.index.name = \"id\"  # Set index name to 'id'\n",
    "    test_pred.to_csv(output_file, index=True)\n",
    "    print(f\"Predictions saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Script Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Data Preparation\n",
    "    X_train, y_train, X_test = load_and_preprocess_data()\n",
    "\n",
    "    # Evaluate model with K-Fold cross-validation\n",
    "    evaluate_with_kfold(X_train, y_train, k=5)\n",
    "\n",
    "    # Train on the full dataset and generate predictions\n",
    "    train_and_predict(X_train, y_train, X_test, output_file=\"y_pred_StackingModel.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
